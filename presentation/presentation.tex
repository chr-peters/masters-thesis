\documentclass[gray]{beamer}

\usefonttheme{serif}
\setbeamerfont{title}{series=\bfseries,parent=structure}
\setbeamerfont{frametitle}{series=\bfseries,parent=structure}
\setbeamertemplate{itemize items}[circle]

\setbeamertemplate{footline}
{
  \hbox{\begin{beamercolorbox}[wd=1\paperwidth,ht=2.25ex,dp=1ex,right]{framenumber}%
      \usebeamerfont{framenumber}\insertframenumber{} / \inserttotalframenumber\hspace*{2ex}
    \end{beamercolorbox}}%
  \vskip0pt%
}

\beamertemplatenavigationsymbolsempty

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsthm,amsmath,amsfonts}

\title{Probit Regression for Large Data Sets via Coresets}
\author{Alexander Munteanu \and Simon Omlor \and Christian Peters}
\institute{TU Dortmund University, Germany}
\date{December 18, 2021}

\begin{document}

\begin{frame}[noframenumbering]
    \thispagestyle{empty}
    \maketitle
\end{frame}

\begin{frame}{Probit Regression}
    \textbf{Data:}
    \begin{itemize}
        \item $n$ observations: $x_1, \ldots, x_n \in \mathbb{R}^d$ \\
        \item with $n$ labels: $y_1, \ldots, y_n \in \{-1, 1\}$
    \end{itemize}

    \vspace{\fill}

    \textbf{Model:}
    \begin{itemize}
        \item $y_1, \ldots, y_n$ are realizations of $Y_1, \ldots, Y_n$
        \item $Y_i \sim Bin(1, \pi_i), \quad \pi_i = \Phi(x_i^T \beta)$
        \item $\Phi(\cdot)$ is cdf of standard normal distribution
    \end{itemize}

    \vspace{\fill}

    \textbf{Loss function:}
    \begin{equation*}
        f(\beta) = \sum_{i=1}^n \ln\left( \frac{1}{\Phi(y_ix_i^T\beta)} \right)
    \end{equation*}
\end{frame}

\begin{frame}{The Problem}
    \textbf{Problems with large datasets:}
    \begin{itemize}
        \item Data doesn't fit into main memory
        \item Limited access to the data (e.g. data streams)
    \end{itemize}

    \vspace{\fill}

    \textbf{Scenarios where this can happen:%
        \footnote{see e.g. \cite{big-data-tiny-data}}}
    \begin{itemize}
        \item Sensor data from mobile devices, cameras, ...
        \item Internet logs
        \item Financial data
    \end{itemize}

    \vspace{\fill}

    \textbf{$\Rightarrow$ Conventional optimization algorithms become inefficient!}
\end{frame}

\begin{frame}{Our Solution}
    \textbf{Select only a small subset (coreset) of the data!} \\
    $\Rightarrow$ Fit the model on the coreset.

    \vspace{\fill}

    \textbf{Challenges:}
    \begin{itemize}
        \item Results on coreset must be close to results on original data
              \begin{itemize}
                  \item[$\Rightarrow$] Need theoretical guarantees!
              \end{itemize}
        \item Coreset must be significantly smaller than original data
              \begin{itemize}
                  \item[$\Rightarrow$] Otherwise useless!
              \end{itemize}
    \end{itemize}

    \vspace{\fill}

    \textbf{Main Goal: Develop efficient coreset construction algorithms!}
\end{frame}

\begin{frame}{The coresets we want...}
    \textbf{(1) ...approximate the data well:}
    \begin{itemize}
        \item Let $f(\beta)$ be the original loss and $\tilde{f}(\beta)$
              be the loss on the coreset
        \item Then for $\epsilon > 0$ and for all $\beta \in \mathbb{R}^d$ we want:
              \begin{equation*}
                  (1 - \epsilon) f(\beta) \leq \tilde{f}(\beta) \leq (1 + \epsilon) f(\beta)
              \end{equation*}
        \item This criterion will guarantee our approximation quality!
    \end{itemize}

    \vspace{\fill}

    \textbf{(2) ...are significantly smaller than our data:}
    \begin{itemize}
        \item Coreset sizes in $O(\log(n))$ would be a great success
        \item Given a dataset with $n=1,000,000,000$ observations,
              $\log(n) \leq 21$
    \end{itemize}
\end{frame}

\begin{frame}{Our first obstacle}
    \textbf{Not every data set allows for small coresets.}
    \begin{itemize}
        \item Shown in \cite{on-coresets} for logistic regression,
              but proof is the same for probit regression
    \end{itemize}

    \vspace{\fill}

    \textbf{$\Rightarrow$ Need to restrict the class of data sets under study!}
    \begin{itemize}
        \item Slightly adapt the concept of $\mu$-complexity from
              \cite{on-coresets} to probit regression
    \end{itemize}
\end{frame}

\begin{frame}{$\mu$-Complexity}
    \begin{equation*}
        \mu = \sup_{\beta \in \mathbb{R}^d \setminus \{0\} }
        \frac{\sum_{y_ix_i^T\beta > 0} (x_i^T \beta)^2}
        {\sum_{y_ix_i^T\beta < 0}(x_i^T \beta)^2}
    \end{equation*}
\end{frame}

\begin{frame}[allowframebreaks, noframenumbering]{Literature}
    \nocite{*}
    \bibliographystyle{apalike}
    \bibliography{../literature}
\end{frame}

\end{document}
