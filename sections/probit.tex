\section{The Probit Model}

The probit model is a special case of the generalized linear model (GLM)
described in~\cite{glm-nelder}.
It is a statistical method for analyzing binary data sets,
which we introduce in the following definition.

\begin{definition}[Data set]
    Let $\mathcal{D} = \{(x_i, y_i)\}_{i=1}^n$ be a set containing
    $n \in \mathbb{N}$ pairs of observations $x_i \in \mathbb{R}^d$,
    $y_i \in \{0, 1\}$.
    We call $\mathcal{D}$ a $d$-dimensional (binary) data set.
\end{definition}

\noindent We can use this definition of a data set
(we will omit the term binary from now on since we will only be dealing
with binary datasets in this work), to describe a whole range of possible scenarios
that can be subjected to statistical analysis.
For example, the $x_i$ could represent some information of a patient, such as
blood pressure or weight, and the $y_i$ could indicate the presence or
the absence of a heart disease.

In situations like this, we are often interested in modeling the
relationship between the explanatory quantities $x_i$ and the
outcomes $y_i$.
We need models, that can help us to answer questions about the data
such as "Which factors increase/decrease the risk of suffering from a heart disease?",
or "How likely is it that a given patient will suffer from a heart disease?".
The probit model is one of many approaches to model such a
relationship in a probabilistic manner.
It is described in detail in references like~\cite{glm-nelder},
\cite{glm-agresti} or \cite{regression-fahrmeir}.

We will outline the core assumptions of the probit model below,
but instead of directly starting with its GLM formulation, we introduce
it as a so-called latent variable model, which enables us to
naturally arrive at not only its GLM specification, but also
at a powerful sampling algorithm that enables us to efficiently apply
the probit model in the realm of bayesian data analysis.

\subsection{Introduction as a Latent Variable Model}
\label{sec:probit-introduction}

When using a probit model to analyze a $d$-dimensional data set
$\mathcal{D} = \{(x_i, y_i)\}_{i=1}^n$, we implicitly
make a set of assumptions on how the data was generated.
Since it is reasonable to assume, that there is a degree of randomness
involved in the data generating process, we model the $y_i$ as realizations
of independent random variables $Y_i$.
This already brings us to the first assumption of the probit model:
We assume that the outcomes $y_i$ were generated independently
from each other, i.e. the occurence of one outcome did not affect
the other outcomes.

The second assumption of the probit model is that there is
a hidden random quantity
$Y_i^\ast$ that is associated with each $Y_i$ such that it
directly determines its outcome:
\begin{equation}
    Y_i =
    \begin{cases}
        1, & \text{if}\ Y_i^\ast > 0    \\
        0, & \text{if}\ Y_i^\ast \leq 0
    \end{cases}
\end{equation}

\noindent The $Y_i^\ast$ are also assumed to be independent from each
other and, as already noted, unobservable.
This is why the $Y_i^\ast$ are also called latent variables and
why the probit model can also be thought of as a latent variable model.

The third and final assumption of the probit model defines the
distribution of the $Y_i^\ast$ and its part of the relationship
between the non-random explanatory quantities $x_i$ and the outcomes $y_i$.
In order to describe this relationship more concisely,
we put all the observations $x_i$ inside of a
matrix $X \in \mathbb{R}^{n \times d}$ in such a way that
the $i$-th row of $X$ corresponds to $x_i$.
In the literature, this matrix $X$ is often called the \textit{model matrix}
(see for example~\cite{glm-agresti}).
We do the same with the $Y_i^\ast$ and put them in a
random vector $Y^\ast$ as well, such that $Y_i^\ast$ constitutes
the $i$-th element of $Y^\ast$.

We are now ready for the third assumption of the probit model:
The explanatory variables
$x_i$ influence $Y_i^\ast$ in the form of a classical linear model:
\begin{equation}
    Y^\ast = X \beta + \epsilon, \quad \epsilon \sim \mathcal{N}(0, \sigma^2 I),
\end{equation}
where $\beta \in \mathbb{R}^d$ is the parameter vector of the linear model,
$\epsilon$ is a normal distributed vector with independent components of
mean zero and variance $\sigma^2$,
and
$I \in \mathbb{R}^{n \times n}$ is the $n \times n$ identity matrix.
It follows directly that $Y^\ast$ is also normal distributed:
$Y^\ast \sim \mathcal{N}(X \beta, \sigma^2 I)$.

These three assumptions are already a complete specification of the
probit model and are summarized in the following definition as a
brief recapitulation:

\begin{definition}[Probit Model]
    A $d$-dimensional binary dataset $\mathcal{D} = \{(x_i, y_i)\}_{i=1}^n$
    with model matrix
    $X \in \mathbb{R}^{n \times d}$ was generated by a probit model with
    parameters $\beta \in \mathbb{R}^d$ and $\sigma \in \mathbb{R}_{>0}$, if
    the following three assumptions are true:
    \begin{enumerate}
        \item The observations $y_1, ..., y_n$ are realizations of independent
              binary random variables $Y_1, ..., Y_n$.
        \item The outcomes of $Y_1, ..., Y_n$ are determined by hidden
              continuous random variables $Y_1^\ast, ..., Y_n^\ast$ by
              thresholding: If $Y_i^\ast > 0$, then $Y_i = 1$, and if
              $Y_i^\ast \leq 0$, then $Y_i = 0$.
        \item The vector of hidden variables $Y^\ast$ follows a multivariate
              normal distribution:
              $Y^\ast \sim \mathcal{N}(X \beta, \sigma^2 I)$,
              where $\beta \in \mathbb{R}^d$ and $\sigma \in \mathbb{R}_{>0}$
              are the model parameters.
    \end{enumerate}
\end{definition}

\noindent Based on this definition, it is straight forward to determine the
distribution of the response variables $Y_i$.
We can calculate the probability $P(Y_i = 1)$ like this:
\begin{equation*}
    P(Y_i = 1) = P(Y_i^\ast > 0) = 1 - P(Y_i^\ast \leq 0)
    = 1 - P\left(\frac{Y_i^\ast - x_i \beta}{\sigma} \leq -\frac{x_i \beta}{\sigma} \right)
    = \Phi\left(\frac{x_i \beta}{\sigma} \right),
\end{equation*}
where $\Phi(\cdot)$ is the cumulative distribution function of the standard normal
distribution:
\begin{equation*}
    \Phi(x) = \int_{-\infty}^x \frac{1}{\sqrt{2 \pi}} e^{- \frac{1}{2} z^2} dz.
\end{equation*}

\noindent This result $P(Y_i = 1) = \Phi\left(\frac{x_i \beta}{\sigma} \right)$
leads us to an interesting observation:
Both parameters $\beta$ and $\sigma$ are unknown model parameters and
every value of $\sigma$ can be compensated by a corresponding scaling
of $\beta$. This means that, because we can't observe the hidden variables $Y_i^\ast$,
it is impossible to determine which $\beta$ and which $\sigma$
generated the data without any prior knowledge.
We can only draw conclusions with regard to the
scaled parameter $\frac{1}{\sigma}\beta$.
In this situation, we say that $\beta$ and $\sigma$ are
\textit{not identifiable}.

For this reason, in literature like~\cite{regression-fahrmeir}
or~\cite{glm-agresti}, it is
often argued that without the loss of generality we can assume that
$\sigma = 1$ and arrive at
\begin{equation*}
    P(Y_i = 1) = \Phi(x_i \beta).
\end{equation*}

\noindent{}Since $Y_i$ is binary, it follows that
\begin{equation*}
    P(Y_i = 0) = 1 - P(Y_i = 1) = 1 - \Phi(x_i \beta) = \Phi(-x_i \beta),
\end{equation*}
which immediately leads us to the model equations:
\begin{equation}
    \label{eq:probit-model}
    Y_i \sim Bin(1, \pi_i), \quad \pi_i = \Phi(x_i \beta),
\end{equation}
where $Bin(1, \pi_i)$ is a bernoulli distribution with success
probability $\pi_i = \Phi(x_i \beta)$.

\subsection{A Special Case of the Generalized Linear Model}

The final equations of the probit model that we arrived at
in equation~\ref{eq:probit-model} are a special case of a more
general model concept, the generalized linear model (GLM),
that we briefly touch on below.

Generalized linear models consist of three components.
The first one is the so called \textit{random component},
a set of $n \in \mathbb{N}$ independent random variables $\{ Y_i \}_{i=1}^n$.
In GLMs, the distribution of these random variables is assumed
to be a member of the \textit{exponential family}, a broad family of
probability distributions that encompasses the normal distribution,
the binomial distribution and many others.
It is characterized in more detail in~\cite{glm-agresti}.

The second component of a GLM is the \textit{linear predictor}.
Just like in the probit model, we also assume that we are
presented with some fixed observations $\{x_i \in \mathbb{R}^d\}_{i=1}^n$,
that are assumed to have some explanatory power with regard to
the $Y_i$. We thus call these observations the explanatory quantities.
The linear predictor will be used to relate the explanatory quantities
to the distribution of the $Y_i$ by linearly combining them as follows:
\begin{equation*}
    \eta_i = x_i \beta,
\end{equation*}
where $\eta_i \in \mathbb{R}$ denotes the linear predictor related
to observation $x_i$ and
$\beta \in \mathbb{R}^d$ is the unknown parameter vector of the GLM
that has to be estimated when fitting the model.

The third component of a GLM is the so called \textit{link function}.
This is a monotonic and differentiable function
$g$
that connects the linear predictor $\eta_i$ to the distribution of the
$Y_i$ like this:
\begin{equation*}
    g(E[Y_i]) = \eta_i.
\end{equation*}
We are thus using the link function $g$ to transform the expected value
$E[Y_i]$ in such a way that it can be predicted by a linear model,
hence the name \textit{generalized linear models}.

Equivalently, we can also characterize this relationsthip by using
the inverse function $h = g^{-1}$,
also called the \textit{response function}:
\begin{equation*}
    E[Y_i] = h(\eta_i).
\end{equation*}

We are now ready to establish the connection between the probit model and
the generalized linear model.
As we saw in equation~\ref{eq:probit-model}, the assumptions of the
probit model imply that the $Y_i$ follow independent binomial distributions
with a success probability of $\pi_i = \Phi(x_i \beta)$.
The binomial distribution is a member of the exponential family, so
we can also think of the $Y_i$ as the random component of a GLM.

It also follows directly from the binomial distribution that
$E[Y_i] = \pi_i$, thus we have from the probit model equations that
$\pi_i = E[Y_i] = \Phi(x_i \beta)$, and equivalently
$\Phi^{-1}(E[Y_i]) = x_i \beta$. Thus, we can think of $\Phi$ as the response
function of a GLM and $\Phi^{-1}$ as the link function, which completes
the specification of the probit model as a special case of GLMs.

\subsection{Parameter Estimation}
\label{sec:parameter-estimation}

Generalized linear models and therefore the probit model are usually
estimated by using the \textit{maximum likelihood method}.
This method seeks to maximize the liklihood that some observed
data set $\mathcal{D} = \{(x_i, y_i)\}_{i=1}^n$ was generated under the
assumptions of the model, given some parameter vector
$\beta \in \mathbb{R}^d$.

To make notation a little easier, we also put the outcomes $y_i$
in a vector $y \in \{0, 1\}^n$ such that $y_i$ is the $i$-th
component of $y$. In the same way, we also put the random
variables $Y_i$ inside of a random vector $Y$.

In the probit model, the likelihood function is given as
\begin{equation}
    \label{eq:likelihood}
    \mathcal{L}(\beta) = P(Y=y ; \beta) = \prod_{i=1}^n P(Y_i=y_i ; \beta),
\end{equation}
because the $Y_i$ are independent. By using a little trick, we can
write $P(Y_i=y_i;\beta)$ like this:
\begin{equation*}
    P(Y_i = y_i ; \beta) = \Phi[(2y_i - 1) x_i \beta],
\end{equation*}
which enables us to arrive at the likelihood
\begin{equation}
    \mathcal{L}(\beta) = \prod_{i=1}^n P(Y_i=y_i ; \beta)
    = \prod_{i=1}^n \Phi[(2y_i - 1) x_i \beta]
    = \prod_{i=1}^n \Phi(- z_i \beta).
\end{equation}
Here, we introduced the new vector $z_i = - (2y_i - 1) x_i$, which will
simplify the notation later on.

The maximum likelihood estimate for $\beta$ is then given by
\begin{equation}
    \label{eq:maximum-likelihood-estimate}
    \hat{\beta} = \underset{\beta \in \mathbb{R}^d}{\operatorname{argmax}}\
    \mathcal{L}(\beta),
\end{equation}
and for $n \rightarrow \infty$ it holds that
$E[\hat{\beta}] = \beta$ \cite{regression-fahrmeir}.

However, for finite sample sizes, the existence of $\hat{\beta}$
cannot be guaranteed and is dependent on the observed data.
An overview of the conditions for the existence and uniqueness of
$\hat{\beta}$ is given in~\cite{probit-computational}.
In particular, there is one important condition shown
in~\cite{probit-existence}, that is related to the concept of
linear separability, which we introduce in the following definition.
\begin{definition}[Linear separability]
    \label{def:linear-separability}
    Let $\mathcal{D}=\{(x_i, y_i)\}_{i=1}^n$ be a $d$-dimensional
    binary dataset.
    Let $S_0 = \{i \in [n]:\ y_i = 0\}$ and $S_0 = \{i \in [n]:\ y_i = 1\}$.
    If there exists a $\beta \in \mathbb{R}^d$ such that
    \begin{equation*}
        \forall i \in S_0:\ x_i \beta \leq 0\quad \text{and}\quad \forall i \in S_1:\ x_i \beta > 0,
    \end{equation*}
    then we call $\mathcal{D}$ linearly separable.
\end{definition}

\noindent Intuitively speaking, a dataset is linearly separable if there
exists a hyperplane that perfectly separates the datapoints labeled
with $1$ from the datapoints labeled with $0$.
This property of a dataset is a both sufficient and
necessary condition for the existence of the
maximum likelihood estimate $\hat{\beta}$ as stated in the following
theorem.

\begin{theorem}[\cite{probit-existence}]
    \label{theorem:probit-existence}
    Let $\mathcal{D}=\{(x_i, y_i)\}_{i=1}^n$ be a $d$-dimensional
    binary dataset and let
    $X \in \mathbb{R}^{n \times d}$ be the corresponding model matrix.
    Under the condition that $rank(X)=d$, i.e. $X$ has full column-rank,
    the maximum likelihood estimate $\hat{\beta}$ for the
    parameter $\beta$ of the probit model
    exists if and only if $\mathcal{D}$ is not linearly separable.
\end{theorem}

\noindent Theorem~\ref{theorem:probit-existence} states,
that the maximum likelihood estimate always exists if the dataset
is not linearly separable, provided the model matrix $X$ has
full column-rank.

\noindent In \cite{wedderburn}, it was further shown, that if the maximum likelihood
estimate exists, then it is also unique.
It now remains to explore, how the maximum likelihood optimization
problem can be solved in such a case.

\subsubsection{Finding the Maximum Likelihood Estimate}

For the reason that the likelihood function $\mathcal{L}(\beta)$ is
numerically inconvenient to maximize, the natural logarithm is often
applied as a transformation to simplify the optimization problem:
\begin{equation}
    \ell(\beta) = \ln \mathcal{L}(\beta) = \sum_{i=1}^n \ln \Phi(- z_i \beta).
\end{equation}

\noindent Since we later wish to interpret $\ell$ as a loss function, we prefer
to minimize the negative value of $\ell$ rather than maximizing:
\begin{equation}
    f(\beta) = -\ell(\beta)
    = \sum_{i=1}^n \ln \left( \frac{1}{1 - \Phi(z_i \beta)} \right)
    = \sum_{i=1}^n g(z_i \beta).
\end{equation}
Here, we define $g(x) = \ln \left(\frac{1}{1 - \Phi(x)}\right)$
and call it the \textit{probit loss}, i.e. the loss-function that
determines how much each $z_i$ contributes to the total loss $f(\beta)$
for a given value of $\beta$.
We call $f(\beta)$ the objective function of the probit model.

The optimization of $f$ is usually done by applying the
Newton-Raphson algorithm, an iterative procedure that
starts at some initial guess $\beta^{(0)}$ and successively
updates it like this:
\begin{equation}
    \beta^{(t)} = \beta^{(t-1)} - \left(\frac{\partial^2f(\beta^{(t-1)})}{\partial\beta\partial\beta^T}\right)^{-1}
    \cdot \frac{\partial f(\beta^{(t-1)})}{\partial\beta},
\end{equation}
where $\left(\frac{\partial^2f(\beta^{(t-1)})}{\partial\beta\partial\beta^T}\right)^{-1}$
refers to the inverse of the hessian matrix of $f$, evaluated at
$\beta^{(t-1)}$, and $\frac{\partial f(\beta^{(t-1)})}{\partial\beta}$
refers to the gradient of $f$, evaluated at $\beta^{(t-1)}$.
The idea behind this procedure is, broadly speaking, to approximate
$f$ locally around $\beta^{(t)}$ as a second degree taylor-polynomial and then
analytically find the minimum of this polynomial. The minimum of this
local polynomial approximation of $f$ is then
iteratively used as the basis for the next step of the
Newton-Raphson algorithm.

It remains to find the gradient as well as the hessian matrix of $f$.
Because $f$ is a sum of the function $g$ evaluated at different points,
it makes sense to first determine the derivative of $g$.
This can be accomplished by using the chain rule as follows:
\begin{equation}
    \begin{split}
        \frac{d}{dx}g(x)
        & = \frac{d}{dx} \ln \left(\frac{1}{1 - \Phi(x)}\right)                 \\
        & = (1 - \Phi(x)) \cdot \frac{d}{dx} \left(\frac{1}{1 - \Phi(x)}\right) \\
        & = (1 - \Phi(x)) \cdot \frac{(-1)}{(1 - \Phi(x))^2} \cdot \frac{d}{dx} (1 - \Phi(x)) \\
        & = \frac{(-1)}{1 - \Phi(x)} \cdot (-1) \cdot \phi(x) \\
        & = \frac{\phi(x)}{1 - \Phi(x)},
    \end{split}
\end{equation}
where $\phi(x)$ is the density function of the standard normal distribution function:
\begin{equation*}
    \phi(x) = \frac{1}{\sqrt{2 \pi}} e^{-\frac{1}{2} x^2}.
\end{equation*}

\noindent We can use this result to calculate the gradient of $f$:
\begin{equation}
    \begin{split}
        \frac{\partial}{\partial \beta} f(\beta)
        & = \frac{\partial}{\partial \beta} \sum_{i=1}^n g(z_i \beta) \\
        & = \sum_{i=1}^n z_i \cdot \frac{\partial}{\partial \beta} g(z_i \beta) \\
        & = \sum_{i=1}^n z_i \cdot \frac{\phi(z_i\beta)}{1 - \Phi(z_i \beta)}
    \end{split}
\end{equation}

\noindent Next, we need to determine the hessian matrix of $f$. In order to do this,
we again start by finding the second derivative of $g$, this time
using the quotient rule:
\begin{equation}
    \begin{split}
        \frac{d^2}{dx^2}g(x)
        & = \frac{d}{dx} \frac{\phi(x)}{1 - \Phi(x)} \\
        & = \frac{\phi'(x)(1 - \Phi(x)) - \phi(x) \cdot (-1) \cdot \phi(x)}
        {(1 - \Phi(x))^2} \\
        & = \frac{(-1) \cdot x \cdot \phi(x)(1 - \Phi(x)) - \phi(x) \cdot (-1) \cdot \phi(x)}
        {(1 - \Phi(x))^2} \\
        & = \frac{[\phi(x)]^2 - x \cdot \phi(x) \cdot (1 - \Phi(x))}{(1 - \Phi(x))^2} \\
        & = \left(\frac{\phi(x)}{1 - \Phi(x)}\right)^2 - x \cdot \frac{\phi(x)}{1 - \Phi(x)} \\
        & = \frac{\phi(x)}{1 - \Phi(x)} \left( \frac{\phi(x)}{1 - \Phi(x)} - x \right)  \\
        & = g'(x) \cdot (g'(x) - x)
    \end{split}
\end{equation}
We can now use this result to find the hessian matrix of $f$:
\begin{equation}
    \begin{split}
        \frac{\partial^2}{\partial \beta \partial \beta^T} f(\beta)
        & = \sum_{i=1}^n
        \frac{\partial^2}{\partial \beta \partial \beta^T} g(z_i \beta)\\
        & = \sum_{i=1}^n z_i z_i^T g'(z_i \beta)(g'(z_i \beta) - z_i \beta)\\
        & = \sum_{i=1}^n z_i z_i^T
        \frac{\phi(z_i \beta)}{1 - \Phi(z_i \beta)} \left( \frac{\phi(z_i \beta)}{1 - \Phi(z_i \beta)} - z_i \beta \right).
    \end{split}
\end{equation}

\noindent Because it can be shown that,
if the maximum likelihood estimate exists,
$f(\beta)$ is a convex function~\cite{wedderburn},
and that the newton raphson algorithm converges to
the global optimum when applied to a convex
function~\cite{numerical-optimization},
the optimization procedure converges to the
maximum likelihood estimate $\hat{\beta}$ under the conditions that
$X$ has full column rank and that the data is not linearly separable.

\subsection{The Bayesian Perspective}

The most fundamental difference between the bayesian approach to
the probit model and the frequentist approach that was discussed above,
is the assumption, that the model parameter $\beta$ is not a fixed
value, but a random variable with a probability distribution.
The goal of bayesian data analysis is to draw conclusions about
the distribution of the model parameter and to update these
conclusions after observing more and more data.

A detailed overview of the principles of bayesian data
analysis would certainly go beyond the scope of this work,
but the interested reader will find a comprehensive reference
in \cite{bayes-gelman}.
In this section, we will merely touch on the most essential concepts,
which are required in order to understand the bayesian view on the
probit model.

\subsubsection{Prior and Posterior Distributions}

To characterize the prior uncertainty about the model parameter $\beta$,
the first step of bayesian data analysis is to specify a so called
\textit{prior distribution}.
In the probit model, one common choice that is also described
in~\cite{regression-fahrmeir} is to assume that
\begin{equation}
    \beta \sim \mathcal{N}(\mu_\beta, \Sigma_\beta),
\end{equation}
i.e. $\beta$ follows a normal distribution with mean
$\mu_\beta \in \mathbb{R}^d$ and
covariance matrix $\Sigma_\beta \in \mathbb{R}^{d \times d}$.

We can think of $\mu_\beta$ and $\Sigma_\beta$ as a way to
include prior knowledge into the model.
If such knowledge is not present, we can choose $\mu_\beta$ and
$\Sigma_\beta$ in a more general fashion, perhaps we decide
to set $\mu_\beta = 0$ and $\Sigma_\beta = \sigma_\beta \cdot I$
for a large value of $\sigma_\beta$, which would
be an example of an \textit{uninformative} prior because of
the relatively unrestrictive assumptions.
Alternatively, we could even go as far and also specify prior
distributions on $\mu_\beta$ and $\Sigma_\beta$, which would
lead us into the realm of hierarchical models
(see \cite{bayes-gelman} for more details). But this would definitely
go beyond the scope of this work, which is why we assume from
now on that the values of $\mu_\beta$ and $\Sigma_\beta$
are specified beforehand in a reasonable manner.

The next step in the process of bayesian data analysis
is to determine how we should update our initial prior
assumptions about $\beta$ after we observed some new data
represented by the dataset $\mathcal{D} = \{(x_i, y_i)\}_{i=1}^n$.
Ultimately, the goal is to determine the
\textit{posterior distribution} of $\beta$ given the new data,
represented by the probability density function
$p(\beta | Y=y)$, where $y$ is the
vector of observations and $Y$ is the random vector that we
assumed to have generated these observations in the probit model.

We can find the posterior distribution by making use of the bayes rule:
\begin{equation}
    p(\beta | Y=y) = \frac{p(Y=y | \beta) p(\beta)}{p(Y=y)}.
\end{equation}
This relationship tells us, that in order to arrive at the
posterior distribution, there
are three different parts that we have to combine.

The first part is the likelihood function $p(Y=y|\beta)$,
which we already dealt with in section~\ref{sec:parameter-estimation}, and
the second part is the prior density function $p(\beta)$,
that we assumed to be normal.

The third and most challenging part to compute is the quantity $p(Y=y)$.
We can see why it is so challenging by writing it out:
\begin{equation}
    \begin{split}
        p(Y=y) &= \int p(Y=y|\beta)p(\beta) d\beta \\
        &= \int \prod_{i=1}^n \Phi(- z_i \beta)
        \frac{1}{\sqrt{(2\pi)^d \det{\Sigma_\beta}}}
        \exp{\left(-\frac{1}{2}(\beta - \mu_\beta)^T \Sigma_\beta^{-1}(\beta - \mu_\beta)\right)} d\beta
    \end{split}
\end{equation}
This infinite integral over all possible values of $\beta$
is impossible to solve analytically, which means that
it's impossible to exactly compute the posterior distribution
for the probit model.
But luckily, encountering an intractable integral like this
is quite common in bayesian data analysis, so
there are workarounds that still allow us to analyze the
posterior distribution, even though we are unable
to determine it exactly.

The first consideration is, that we could also analyze the posterior
distribution if we had a large enough sample of it available instead.
When the sample size is big enough, the Glivenko-Cantelli theorem
tells us that the empirical posterior distribution converges
to the true posterior distribution~\cite{glivenko-cantelli}.
This allows us to analyze the posterior
distribution by analyzing a large enough sample of it,
but the problem of how to obtain such a sample still remains.

In practice, instead of directly sampling from $p(\beta | Y=y)$,
the posterior distribution can be approximated by so called
Markov chain Monte Carlo (MCMC) methods.
One such method that works particularly well for the probit model
is the Gibbs sampler, which is described in the next section.

\subsubsection{Gibbs Sampling in the Probit Model}

Gibbs sampling is an iterative tool for drawing samples from
probability distributions, that was first applied in the
context of bayesian
inference by~\cite{gibbs-sampler} and has been adapted to the
probit model by~\cite{gibbs-probit-albert-chib} using the idea
of \textit{data augmentation}, which was first introduced
in~\cite{data-augmentation}.
We describe this idea in the following section, as it yields
an efficient algorithm for sampling from the posterior
distribution of the probit model.

Remember that the probit model has two components: The vector of latent
variables $Y^\ast$ that follows a linear model
$Y^\ast\ |\ \beta\sim \mathcal{N}(X \beta, 1)$, where we assume that $\sigma=1$
for reasons of identifiability (see section~\ref{sec:probit-introduction})
and the random vector $Y$ that produces the observed outcomes $y$ by
thresholding: If $Y_i^\ast > 0$, then $Y_i=1$ and $Y_i=0$ otherwise.
We also assumed a normal prior distribution:
$\beta \sim \mathcal{N}(\mu_\beta, \Sigma_\beta)$.

Now, imagine that we knew the outcomes of the latent variable vector $Y^\ast$.
The conditional distribution of $\beta$ given the realization $y^\ast$
of the latent variables can be shown to be normal~\cite{gibbs-probit-albert-chib}:
\begin{equation}
    \label{eq:gibbs-normal}
    \beta\ |\ Y^\ast = y^\ast\ \sim\ \mathcal{N}(b, B),
\end{equation}
where
$b = (\Sigma_\beta^{-1} + X^TX)^{-1}(\Sigma_\beta^{-1} \mu_\beta + X^T y^\ast)$
and
$B = (\Sigma_\beta^{-1} + X^TX)^{-1}$.
As we can see, the result is a normal distribution from which we can
sample efficiently.

The problem is, that in reality we can't observe the latent variables and
therefore we don't know the realizations $y^\ast$.
Here, an important finding by~\cite{gibbs-probit-albert-chib} comes
into play: If we could observe $\beta$ and see the realization
$\tilde\beta$, then we could determine the conditional distribution
of the latent variable vector $Y^\ast$:
\begin{equation}
    \label{eq:truncated-normal}
    Y_i^\ast\ |\ \beta = \tilde\beta,\ Y_i=y_i\ \sim
    \begin{cases}
        \mathcal{N}(x_i^T\tilde\beta, 1)\ \text{truncated at the left by 0},  & \text{if}\ y_i = 1 \\
        \mathcal{N}(x_i^T\tilde\beta, 1)\ \text{truncated at the right by 0}, & \text{if}\ y_i = 0
    \end{cases}
\end{equation}
This means, that given a realization $\tilde\beta$ and the observed
values in $y$, the latent variables
follow a truncated normal distribution, from which it is also
possible to sample efficiently.

These two observations bring us directly to the Gibbs sampling algorithm
for the probit model. The first step of this procedure is
to determine a starting value $\tilde\beta^{(0)}$.
\cite{gibbs-probit-albert-chib} suggest that this could for example
be the maximum likelihood estimate, that we already discussed in
section~\ref{sec:parameter-estimation}.

The next step of the Gibbs sampling algorithm is to use this value
$\tilde\beta^{(0)}$ to sample a realization ${y^\ast}^{(1)}$ from the latent
variable vector $Y^\ast$, by using the conditional distribution
in equation~\ref{eq:truncated-normal}. Given ${y^\ast}^{(1)}$,
it is then possible to sample a new value $\tilde\beta^{(1)}$ from
the normal distribution in equation~\ref{eq:gibbs-normal},
which starts a new cycle. These two sampling steps, which can
both be carried out efficiently, are repeated until
the desired amount of samples is reached.

To sum up, we augmented the observed data by incorporating the
hidden variables $Y^\ast$ to arrive at a two-stage procedure
that draws alternating samples from the conditional distributions
of $\beta$ and $Y^\ast$, hence the name data augmentation.

\newpage