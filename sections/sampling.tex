\section{Sensitivity Sampling}

\begin{definition}
    Let $Z \in \mathbb{R}^{n \times d}$. Then we define
    $$
        \mu_w(Z) = \sup_{\beta \in \mathbb{R}^d \setminus \{0\}}
        \frac{\left \lVert (\sqrt{D_w} Z \beta)^+ \right \rVert_2^2}
        {\left \lVert (\sqrt{D_w} Z \beta)^- \right \rVert_2^2}
        =
        \sup_{\beta \in \mathbb{R}^d \setminus \{0\}}
        \frac{\left \lVert (\sqrt{D_w} Z \beta)^- \right \rVert_2^2}
        {\left \lVert (\sqrt{D_w} Z \beta)^+ \right \rVert_2^2}
    $$
    Z weighted by $w$ is called $\mu$-complex if $\mu_w(Z) \leq \mu$.
\end{definition}

\begin{definition}[\cite{big-data-tiny-data, origin-of-sensitivities}]
    \label{def:sensitivity}
    Let $F = \{ g_1, ..., g_n \}$ be a set of functions,
    $g_i: \mathbb{R} \rightarrow \mathbb{R}^{\geq 0}, \ i=1,...,n$ weighted by
    $w \in \mathbb{R}^n_{>0}$.
    The sensitivity of $g_i$ for $f_w(\beta) = \sum_{i=1}^n w_i g_i(\beta)$ is defined as
    \begin{equation*}
        \varsigma_i = \sup_{\beta \in \mathbb{R}^d, \ f_w(\beta) > 0} \frac{w_i g_i(\beta)}{f_w(\beta)}.
    \end{equation*}
    The total sensitivity, i.e. the sum of the sensitivities is $\mathfrak{S} = \sum_{i=1}^n \varsigma_i$.
\end{definition}

\begin{definition}[\cite{big-data-tiny-data}]
    A range space is a pair $\mathfrak{R} = (F, \mathcal{R})$, where F is a set
    and $\mathcal{R}$ is a family (set) of subsets of F, called
    ranges.
\end{definition}

\begin{definition}[\cite{big-data-tiny-data}]
    The VC-dimension $\Delta(\mathfrak{R})$ of a range space $\mathfrak{R} = (F, \mathcal{R})$ is
    the size $|G|$ of the largest subset $G \subseteq F$ such that
    \begin{equation*}
        \left| \left\{ G \cap \textup{range} \ | \ \textup{range} \in \mathcal{R} \right\} \right|
        = 2^{|G|}
    \end{equation*}
\end{definition}

\begin{definition}[\cite{big-data-tiny-data}]
    Let $F$ be a finite set of functions mapping from $\mathbb{R}^d$ to $\mathbb{R}^{\geq 0}$.
    For every $\beta \in \mathbb{R}^d$ and $r \geq 0$, let
    \begin{equation*}
        \textup{range}(F, \beta, r) = \left\{ f \in F \ | \  f(\beta) \geq r  \right\}
    \end{equation*}
    and let
    \begin{equation*}
        \mathcal{R}(F) = \left\{ \textup{range}(F, \beta, r) \ | \ \beta \in \mathbb{R}^d, \ r \geq 0  \right\}.
    \end{equation*}
    Then we call $\mathfrak{R}_F := (F, \mathcal{R}(F))$ the range space induced by F.
\end{definition}

\begin{theorem}[\cite{big-data-tiny-data, on-coresets}]
    Let $\mathcal{F} = \{ f_1, ..., f_n \}$ be a set of functions,
    $f_i: \mathbb{R} \rightarrow \mathbb{R}^{\geq 0}, \ i=1,...,n$ weighted by
    $w \in \mathbb{R}^n_{>0}$.
    Let $\epsilon, \delta \in (0, \frac{1}{2})$.
    Let $s_i \geq \varsigma_i$.
    Let $S = \sum_{i=1}^n s_i \geq \mathfrak{S}$.
    Given $s_i$, one can compute in time $O(|\mathcal{F}|)$ a set
    $\mathcal{R} \subseteq \mathcal{F}$ of
    \begin{equation*}
        O \left( \frac{S}{\epsilon^2} \left( \Delta \log S + \log \left( \frac{1}{\delta} \right) \right) \right)
    \end{equation*}
    weighted functions such that with probability $1 - \delta$ we have
    for all $\beta \in \mathbb{R}^d$ simultaneously
    \begin{equation*}
        \left| \sum_{f \in \mathcal{F}} w_i f_i(\beta) - \sum_{f \in \mathcal{R}} u_i f_i(\beta) \right| \leq \epsilon \sum_{f \in \mathcal{F}} w_i f_i(\beta)
    \end{equation*}
    where each element of $\mathcal{R}$ is sampled independently with probability
    $p_j = \frac{s_j}{S}$ from $\mathcal{F}$, $u_i = \frac{S w_j}{s_j |\mathcal{R}|}$
    denotes the weight of a function $f_i \in \mathcal{R}$ that corresponds to
    $f_j \in \mathcal{F}$, and where $\Delta$ is an upper bound on the
    VC-dimension of the range space $\mathfrak{R}_{\mathcal{F}^*}$ induced by
    $\mathcal{F}^*$. $\mathcal{F}^*$ is the set of functions $f_j \in \mathcal{F}$
    scaled by $\frac{S w_j}{s_j |\mathcal{R}|}$.
\end{theorem}

\begin{lemma}
    Let $Z \in \mathbb{R}^{n \times d}$, $c \in \mathbb{R}_{>0}$.
    The range space induced by
    $$\mathcal{F}^c_{probit} = \{ c g(z_i \beta) \ | \ i \in [n] \}$$
    satisfies $\Delta(\mathfrak{R}_{\mathcal{F}^c_{probit}}) \leq d + 1$.
\end{lemma}
\begin{proof}
    For all $G \subseteq \mathcal{F}^c_{probit}$ we have
    \begin{equation*}
        \left| \left\{ G \cap \textup{range} \ | \
        \textup{range} \in \mathcal{R}(\mathcal{F}^c_{probit}) \right\} \right|
        =
        \left| \left\{ \textup{range}(G, \beta, r) \ | \
        \beta \in \mathbb{R}^d, \ r \geq 0 \right\} \right|
    \end{equation*}
    Since $g$ is invertible and monotone, we have for all
    $\beta \in \mathbb{R}^d$ and $r \geq 0$ that
    \begin{align*}
        \textup{range}(G, \beta, r)
         & = \left\{ g_i \in G \ |\ g_i(\beta) \geq r \right\}                                 \\
         & = \left\{ g_i \in G \ |\ c g(x_i \beta) \geq r \right\}                             \\
         & = \left\{ g_i \in G \ |\ x_i \beta \geq g^{-1} \left( \frac{r}{c} \right) \right\}.
    \end{align*}
    Note, that $\left\{ g_i \in G
        \ |\ x_i \beta \geq g^{-1} \left( \frac{r}{c} \right) \right\}$
    corresponds to the positively classified points of the
    affine hyperplane classifier
    $x \mapsto \textup{sign}\left(
        x\beta - g^{-1}\left(\frac{r}{c}\right) \right)$.
    We thus have for all $G \subseteq \mathcal{F}_{probit}^c$, that
    \begin{equation*}
        \left| \left\{ G \cap \textup{range} \ | \
        \textup{range} \in \mathcal{R}(\mathcal{F}^c_{probit}) \right\} \right|
        =
        \left| \left\{ \left\{ g_i \in G
        \ |\ x_i \beta - s \geq 0 \right\} \ | \
        \beta \in \mathbb{R}^d, \ s \in \mathbb{R} \right\} \right|.
    \end{equation*}
    Since the VC dimension of the set of affine hyperplane classifiers is
    $d+1$, it follows that
    \begin{equation*}
        \max_{G \subseteq \mathcal{F}_{probit}^c}
        \left| \left\{ G \cap \textup{range} \ | \
        \textup{range} \in \mathcal{R}(\mathcal{F}^c_{probit}) \right\} \right|
        \leq d + 1,
    \end{equation*}
    which concludes our proof.
\end{proof}

\begin{lemma}
    Let $Z \in \mathbb{R}^{n \times d}$ weighted by $w \in \mathbb{R}^n_{>0}$
    be $\mu$-complex. Let $U$ be an orthonormal basis for the columnspace
    of $\sqrt{D_w} Z$. If for index $i$, the supreme $\beta$ in definition \ref{def:sensitivity} satisfies
    $2 \leq z_i \beta$, then
    $w_i g(z_i \beta) \leq 2 \lVert U_i \rVert_2^2 (1 + \mu) f_w(\beta)$.
\end{lemma}
\begin{proof}
    Let $\sqrt{D_w} Z = UR$, where $U$ is an orthonormal basis for the columnspace
    of $\sqrt{D_w} Z$. It follows from $2 \leq z_i \beta$ and from the monotonicity
    of $g$ that
    \begin{align*}
        w_i g(z_i \beta)
         & = w_i g\left(\frac{\sqrt{w_i} z_i \beta}{\sqrt{w_i}}\right)
        = w_i g\left(\frac{U_i R \beta}{\sqrt{w_i}}\right)
        \leq w_i g\left(\frac{\lVert U_i \rVert_2 \lVert R \beta \rVert_2}{\sqrt{w_i}}\right)               \\
         & = w_i g\left(\frac{\lVert U_i \rVert_2 \lVert U R \beta \rVert_2}{\sqrt{w_i}}\right)
        = w_i g\left(\frac{\lVert U_i \rVert_2 \lVert \sqrt{D_w} Z \beta \rVert_2}{\sqrt{w_i}}\right)       \\
         & \leq \lVert U_i \rVert_2^2 \lVert \sqrt{D_w} Z \beta \rVert_2^2
        \leq \lVert U_i \rVert_2^2 (1 + \mu) \lVert (\sqrt{D_w} Z \beta)^+ \rVert_2^2                       \\
         & = \lVert U_i \rVert_2^2 (1 + \mu) \sum_{j: \  \sqrt{w_j} z_j \beta \geq 0} w_j (z_j \beta)^2     \\
         & \leq 2 \lVert U_i \rVert_2^2 (1 + \mu) \sum_{j: \  \sqrt{w_j} z_j \beta \geq 0} w_j g(z_j \beta) \\
         & \leq 2 \lVert U_i \rVert_2^2 (1 + \mu) \sum_{j = 1}^n w_j g(z_j \beta)                           \\
         & = 2 \lVert U_i \rVert_2^2 (1 + \mu) f_w(\beta)
    \end{align*}
\end{proof}

\begin{lemma}
    Let $Z \in \mathbb{R}^{n \times d}$ weighted by $w \in \mathbb{R}^n_{>0}$
    be $\mu$-complex. If for index $i$, the supreme $\beta$ in definition \ref{def:sensitivity} satisfies
    $z_i \beta \leq 2$, then
    $w_i g(z_i \beta) \leq \frac{w_i}{\mathcal{W}} (80 + 16 \mu) f_w(\beta)$.
\end{lemma}
\begin{proof}
    Let $K^- = \{ j \in [n] \ | \ z_j \beta \leq -1 \}$ and
    $K^+ = \{ j \in [n] \ | \ z_j \beta > -1 \}$.
    Note that $g(-1) > \frac{1}{10}$ and
    $g(z_i \beta) \leq g(2) < 4$.
    Also, $\sum_{j \in K^+} w_j + \sum_{j \in K^-} w_j = \mathcal{W}$.
    \\
    Thus, if $\sum_{j \in K^+} w_j \geq \frac{1}{2} \mathcal{W}$ then
    $$
        f_w(\beta) = \sum_{j=1}^n w_j g(z_j \beta)
        \geq \sum_{j \in K^+} w_j g(z_j \beta)
        \geq \frac{\sum_{j \in K^+} w_j}{10}
        \geq \frac{\mathcal{W}}{20}
        = \frac{\mathcal{W}}{20 w_i} w_i
        \geq \frac{\mathcal{W}}{80 w_i} w_i g(z_i \beta)
    $$
    If on the other hand $\sum_{j \in K^+} w_j < \frac{1}{2} \mathcal{W}$,
    then $\sum_{j \in K^-} w_j \geq \frac{1}{2} \mathcal{W}$. Thus
    \begin{align*}
        f_w(\beta)
         & = \sum_{j=1}^n w_j g(z_j \beta)
        \geq \sum_{j: \  z_j \beta > 0} w_j g(z_j \beta)
        \geq \frac{1}{2} \sum_{j: \  z_j \beta > 0} w_j (z_j \beta)^2    \\
         & = \frac{1}{2} \lVert (\sqrt{D_w} Z \beta)^+ \rVert_2^2
        \geq \frac{1}{2 \mu} \lVert (\sqrt{D_w} Z \beta)^- \rVert_2^2    \\
         & = \frac{1}{2 \mu} \sum_{j: \ z_j \beta < 0} w_j (z_j \beta)^2 \\
         & \geq \frac{1}{2 \mu} \sum_{j \in K^-} w_j (z_j \beta)^2       \\
         & \geq \frac{1}{2 \mu} \sum_{j \in K^-} w_j                     \\
         & \geq \frac{\mathcal{W}}{4 \mu}                                \\
         & \geq \frac{\mathcal{W}}{16 \mu w_i} w_i g(z_i \beta)
    \end{align*}
    Adding both bounds, we get that for $z_i \beta \leq 2$:
    $$
        w_i g(z_i \beta) \leq f_w(\beta) \frac{80 w_i}{\mathcal{W}}
        + f_w(\beta) \frac{16 \mu w_i}{\mathcal{W}}
        = \frac{w_i}{\mathcal{W}} (80 + 16 \mu) f_w(\beta)
    $$
\end{proof}

\begin{lemma}
    Let $Z \in \mathbb{R}^{n \times d}$ weighted by $w \in \mathbb{R}^n_{>0}$
    be $\mu$-complex. Let $U$ be an orthonormal basis for the columnspace
    of $\sqrt{D_w} Z$.
    For each $i \in [n]$, the sensitivity of $g_i(\beta) = g(z_i \beta)$
    is bounded by
    $\varsigma_i \leq s_i = (80 + 16\mu)(\lVert U_i \rVert_2^2 + \frac{w_i}{\mathcal{W}})$.
    The total sensitivity is bounded by $\mathfrak{S} \leq 192 \mu d$.
\end{lemma}
\begin{proof}
    \begin{align*}
        \varsigma_i
         & = \sup_{\beta} \frac{w_i g(z_i \beta)}{f_w(\beta)}
        \leq \sup_{\beta} \frac{2 \lVert U_i \rVert_2^2 (1 + \mu) f_w(\beta)
            + \frac{w_i}{\mathcal{W}} (80 + 16 \mu) f_w(\beta)}{f_w(\beta)}                  \\
         & = 2 \lVert U_i \rVert_2^2 (1 + \mu) + \frac{w_i}{\mathcal{W}} (80 + 16 \mu)       \\
         & \leq \lVert U_i \rVert_2^2 (80 + 16 \mu) +  \frac{w_i}{\mathcal{W}} (80 + 16 \mu) \\
         & = (80 + 16\mu)(\lVert U_i \rVert_2^2 + \frac{w_i}{\mathcal{W}})
    \end{align*}
    \begin{align*}
        \mathfrak{S}
         & = \sum_{i=1}^n \varsigma_i \leq (80 + 16\mu) \sum_{i=1}^n \lVert U_i \rVert_2^2 + \frac{w_i}{\mathcal{W}} \\
         & = (80 + 16 \mu)(\lVert U \rVert_F^2 + 1)                                                                  \\
         & = (80 + 16 \mu)(d + 1)                                                                                    \\
         & \leq 96 \mu(d + 1)                                                                                        \\
         & \leq 192 \mu d
    \end{align*}
\end{proof}

\begin{lemma}
    Let $U \in \mathbb{R}^{n \times d}$ be an orthonormal matrix.
    Then $\lVert U \rVert_F^2 = d$.
\end{lemma}
\begin{proof}
    \begin{align*}
        \lVert U \rVert_F^2
         & = \sum_{i=1}^n \sum_{j=1}^d |u_{ij}|^2 \\
         & = \sum_{j=1}^d \sum_{i=1}^n |u_{ij}|^2 \\
         & \overset{(1)}{=} \sum_{j=1}^d 1        \\
         & = d                                    \\
    \end{align*}
    (1) follows from the fact that the columns of $U$ have unit norm
    due to its orthonormality.
\end{proof}