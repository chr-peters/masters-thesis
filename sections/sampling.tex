\subsection{Sensitivity Sampling}



\begin{lemma}
    \label{lemma:vcdim-constant}
    Let $Z \in \mathbb{R}^{n \times d}$, $c \in \mathbb{R}_{>0}$.
    The range space induced by
    $$\mathcal{F}^c_{probit} = \{ c g(z_i \beta) \ | \ i \in [n] \}$$
    satisfies $\Delta(\mathfrak{R}_{\mathcal{F}^c_{probit}}) \leq d + 1$.
\end{lemma}
\begin{proof}
    For all $G \subseteq \mathcal{F}^c_{probit}$ we have
    \begin{equation*}
        \left| \left\{ G \cap \textup{range} \ | \
        \textup{range} \in \mathcal{R}(\mathcal{F}^c_{probit}) \right\} \right|
        =
        \left| \left\{ \textup{range}(G, \beta, r) \ | \
        \beta \in \mathbb{R}^d, \ r \geq 0 \right\} \right|.
    \end{equation*}
    Since $g$ is invertible and monotone, we have for all
    $\beta \in \mathbb{R}^d$ and $r \geq 0$ that
    \begin{align*}
        \textup{range}(G, \beta, r)
         & = \left\{ g_i \in G \ |\ g_i(\beta) \geq r \right\}                                 \\
         & = \left\{ g_i \in G \ |\ c g(x_i \beta) \geq r \right\}                             \\
         & = \left\{ g_i \in G \ |\ x_i \beta \geq g^{-1} \left( \frac{r}{c} \right) \right\}.
    \end{align*}
    Note, that $\left\{ g_i \in G
        \ |\ x_i \beta \geq g^{-1} \left( \frac{r}{c} \right) \right\}$
    corresponds to the positively classified points of the
    affine hyperplane classifier
    $x \mapsto \textup{sign}\left(
        x\beta - g^{-1}\left(\frac{r}{c}\right) \right)$.
    We thus have for all $G \subseteq \mathcal{F}_{probit}^c$, that
    \begin{equation*}
        \left| \left\{ G \cap \textup{range} \ | \
        \textup{range} \in \mathcal{R}(\mathcal{F}^c_{probit}) \right\} \right|
        =
        \left| \left\{ \left\{ g_i \in G
        \ |\ x_i \beta - s \geq 0 \right\} \ | \
        \beta \in \mathbb{R}^d, \ s \in \mathbb{R} \right\} \right|.
    \end{equation*}
    Since the VC dimension of the set of affine hyperplane classifiers is
    $d+1$, it follows that
    $\Delta(\mathfrak{R}_{\mathcal{F}^c_{probit}}) \leq d + 1$,
    which concludes our proof.
\end{proof}

\begin{lemma}
    Let $Z \in \mathbb{R}^{n \times d}$ be weighted by
    $w \in \mathbb{R}^n_{>0}$ where $w_i \in \{ v_1, ..., v_t \}$ for
    all $i \in [n]$.
    The range space induced by
    \begin{equation*}
        \mathcal{F}_{probit} = \left\{ w_ig(z_i\beta) \ |\ i \in [n] \right\}
    \end{equation*}
    satisfies
    $\Delta(\mathfrak{R}_{\mathcal{F}_{probit}}) \leq t \cdot (d + 1)$.
\end{lemma}
\begin{proof}
    We partition the functions of $\mathcal{F}_{probit}$ into $t$ disjoint
    classes
    \begin{equation*}
        F_j = \{ w_ig(z_i\beta) \in \mathcal{F}_{probit} \
        |\ w_i = v_j \},\quad j \in [t].
    \end{equation*}
    The functions in each of these classes have an equal
    weight, wich means that by lemma~\ref{lemma:vcdim-constant}, each of
    their induced range spaces has a VC-dimension of at most $d+1$.

    For the sake of contradiction, assume that
    $\Delta(\mathfrak{R}_{\mathcal{F}_{probit}}) > t \cdot (d + 1)$ and let
    $G$ be the corresponding set of size $|G| > t \cdot (d + 1)$ that
    is shattered by $\mathcal{R}(\mathcal{F}_{probit})$.
    Since the sets $F_j$ are disjoint, each intersection
    $F_j \cap G$ must be shattered by $\mathcal{R}(F_j)$.
    Further, at least one of the intersections must have at minimum
    $\frac{|G|}{t}$ elements, which means that for at least one $j \in [t]$
    it holds that
    $|F_j \cap G| \geq \frac{|G|}{t} > \frac{t \cdot (d+1)}{t} = d + 1$.
    This is a contradiction to lemma~\ref{lemma:vcdim-constant}, which
    concludes the proof.
\end{proof}



\begin{lemma}
    Let $Z \in \mathbb{R}^{n \times d}$ weighted by $w \in \mathbb{R}^n_{>0}$
    be $\mu$-complex. Let $U$ be an orthonormal basis for the columnspace
    of $\sqrt{D_w} Z$.
    For each $i \in [n]$, the sensitivity of $g_i(\beta) = g(z_i \beta)$
    is bounded by
    $\varsigma_i \leq s_i = (80 + 16\mu)(\lVert U_i \rVert_2^2 + \frac{w_i}{\mathcal{W}})$.
    The total sensitivity is bounded by $\mathfrak{S} \leq 192 \mu d$.
\end{lemma}
\begin{proof}
    \begin{align*}
        \varsigma_i
         & = \sup_{\beta} \frac{w_i g(z_i \beta)}{f_w(\beta)}
        \leq \sup_{\beta} \frac{2 \lVert U_i \rVert_2^2 (1 + \mu) f_w(\beta)
            + \frac{w_i}{\mathcal{W}} (80 + 16 \mu) f_w(\beta)}{f_w(\beta)}                  \\
         & = 2 \lVert U_i \rVert_2^2 (1 + \mu) + \frac{w_i}{\mathcal{W}} (80 + 16 \mu)       \\
         & \leq \lVert U_i \rVert_2^2 (80 + 16 \mu) +  \frac{w_i}{\mathcal{W}} (80 + 16 \mu) \\
         & = (80 + 16\mu)(\lVert U_i \rVert_2^2 + \frac{w_i}{\mathcal{W}})
    \end{align*}
    \begin{align*}
        \mathfrak{S}
         & = \sum_{i=1}^n \varsigma_i \leq (80 + 16\mu) \sum_{i=1}^n \lVert U_i \rVert_2^2 + \frac{w_i}{\mathcal{W}} \\
         & = (80 + 16 \mu)(\lVert U \rVert_F^2 + 1)                                                                  \\
         & = (80 + 16 \mu)(d + 1)                                                                                    \\
         & \leq 96 \mu(d + 1)                                                                                        \\
         & \leq 192 \mu d
    \end{align*}
\end{proof}

\begin{lemma}
    Let $U \in \mathbb{R}^{n \times d}$ be an orthonormal matrix.
    Then $\lVert U \rVert_F^2 = d$.
\end{lemma}
\begin{proof}
    \begin{align*}
        \lVert U \rVert_F^2
         & = \sum_{i=1}^n \sum_{j=1}^d |u_{ij}|^2 \\
         & = \sum_{j=1}^d \sum_{i=1}^n |u_{ij}|^2 \\
         & \overset{(1)}{=} \sum_{j=1}^d 1        \\
         & = d                                    \\
    \end{align*}
    (1) follows from the fact that the columns of $U$ have unit norm
    due to its orthonormality.
\end{proof}